{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AdamPang4339/EvaluationOfFederatedLearning/blob/main/DATA_POISONED_VERSION.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_XjP3ijNvmL"
      },
      "source": [
        "Installing Flower dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmxy31xzNT3z",
        "outputId": "7d7f0715-5da9-4599-ed0e-1f7f80bf5c0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torch (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q flwr[simulation] flwr-datasets[vision] torch torchvision matplotlib pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbxON5g2SnnA"
      },
      "source": [
        "Necessary Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "On-Pow8ASs2o",
        "outputId": "6dcdae8d-9882-4443-ac08-0d73253434f5"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "from typing import List, Union, Tuple, Dict, Optional\n",
        "import random\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from datasets.utils.logging import disable_progress_bar\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from collections import OrderedDict\n",
        "\n",
        "import flwr\n",
        "from flwr.server.client_proxy import ClientProxy\n",
        "from flwr.client import Client, ClientApp, NumPyClient\n",
        "from flwr.common import Metrics, Context, EvaluateRes, FitRes, Scalar\n",
        "from flwr.server import ServerApp, ServerConfig, ServerAppComponents\n",
        "from flwr.server.strategy import FedAvg\n",
        "from flwr.simulation import run_simulation\n",
        "from flwr_datasets import FederatedDataset\n",
        "from flwr_datasets.partitioner import NaturalIdPartitioner\n",
        "\n",
        "DEVICE = torch.device(\"cpu\")  # Try \"cuda\" to train on GPU\n",
        "print(f\"Training on {DEVICE}\")\n",
        "disable_progress_bar()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xuymAFbnWkGe"
      },
      "source": [
        "Loading FEMNIST dataset and split up into train, test, and validation sets. Working with 10 clients for our FL model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6iC_-b6_WqnU",
        "outputId": "5173f493-6f5c-4844-fd27-f99fb63cff83"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "NUM_CLIENTS = 10\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "def load_datasets(partition_id: int):\n",
        "  '''\n",
        "  Function loads different parts of the FEMNIST dataset depending on the partition\n",
        "  ID specified as a parameter. We have 10 clients in our simulation, so we will be using\n",
        "  10 partition IDs.\n",
        "  '''\n",
        "  # Split FEMNIST dataset into 10 partitions\n",
        "  fds = FederatedDataset(\n",
        "      dataset=\"flwrlabs/femnist\",\n",
        "      partitioners={\"train\": NUM_CLIENTS}\n",
        "  )\n",
        "  partition = fds.load_partition(partition_id)\n",
        "\n",
        "  # Divide data in each partition: 80% train, 20% test\n",
        "  # Note: We use a set seed to make sure the results are reproducible\n",
        "  partition_train_test = partition.train_test_split(test_size=0.2, seed=21)\n",
        "\n",
        "  # Normalize and convert images to PyTorch tensors for more stable training\n",
        "  pytorch_transforms = transforms.Compose(\n",
        "      [transforms.ToTensor(), transforms.Normalize((0.5), (0.5))]\n",
        "  )\n",
        "\n",
        "  def apply_transforms(batch):\n",
        "    '''\n",
        "    Applies transformations of pytorch_transforms on every image in place\n",
        "    '''\n",
        "    batch[\"image\"] = [pytorch_transforms(img) for img in batch[\"image\"]]\n",
        "\n",
        "    if (partition_id == 0):\n",
        "      for i in range(len(batch[\"character\"]) // 2):\n",
        "        batch[\"character\"][i] = (batch[\"character\"][i] + 1) % 62\n",
        "\n",
        "    return batch\n",
        "\n",
        "  # Create train/val for each partition and wrap it into DataLoader\n",
        "  partition_train_test = partition_train_test.with_transform(apply_transforms)\n",
        "  trainloader = DataLoader(\n",
        "      partition_train_test[\"train\"], batch_size=BATCH_SIZE, shuffle=True\n",
        "  )\n",
        "\n",
        "  # Generate DataLoaders for the validation and test data batches\n",
        "  # Generate testset as the whole dataset\n",
        "  valloader = DataLoader(partition_train_test[\"test\"], batch_size=BATCH_SIZE)\n",
        "  testset = fds.load_split(\"train\").with_transform(apply_transforms)\n",
        "  testloader = DataLoader(testset, batch_size=BATCH_SIZE)\n",
        "\n",
        "  return trainloader, valloader, testloader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zQ2n5eZfFrI"
      },
      "source": [
        "Testing the data load process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "id": "IrlmU04gfFIQ",
        "outputId": "bfc3c1f7-e736-4d0b-c968-2975501e3d64"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "# Testing with partition id 0\n",
        "trainloader, _, _ = load_datasets(partition_id=0)\n",
        "num_images = 10\n",
        "\n",
        "# Get a batch of images\n",
        "batch = next(iter(trainloader))\n",
        "images, labels = batch[\"image\"], batch[\"character\"]\n",
        "\n",
        "# Create a grid of subplots\n",
        "fig, axes = plt.subplots(1, num_images, figsize=(15, 5))\n",
        "\n",
        "for i in range(num_images):\n",
        "    # Get image and label\n",
        "    img = images[i].numpy()  # Convert to numpy array\n",
        "    label = trainloader.dataset.features[\"character\"].int2str([labels[i]])[0]        # Labels have been converted to their characters\n",
        "\n",
        "    # Rescale image back to [0, 1]\n",
        "    img = (img * 0.5) + 0.5  # Unnormalize the image (if using mean=0.5, std=0.5)\n",
        "\n",
        "    # Display image\n",
        "    axes[i].imshow(img.squeeze(), cmap='gray')\n",
        "    axes[i].set_title(f\"Label: {label}\")  # Display label\n",
        "    axes[i].axis('off')  # Hide axes\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ez0d6Z79tdbJ"
      },
      "source": [
        "# Initial Global Model CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TlciuurHtjOO"
      },
      "source": [
        "Model architecture CNN template from https://github.com/TalwalkarLab/leaf/blob/master/models/femnist/cnn.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOmwUu7PthCp",
        "outputId": "3e4d18a3-ab58-4ced-a87b-1d3813bf1c37"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self) -> None:\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 62)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 4 * 4)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05rWpMfquQaJ"
      },
      "source": [
        "Training and testing functions for CNN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5E6Vp8cSH2cU"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "def train(net, trainloader, epochs: int, verbose=False):\n",
        "    \"\"\"Train the network on the training set.\"\"\"\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(net.parameters())\n",
        "    net.train()\n",
        "    for epoch in range(epochs):\n",
        "        correct, total, epoch_loss = 0, 0, 0.0\n",
        "        for batch in trainloader:\n",
        "            images, labels = batch[\"image\"].to(DEVICE), batch[\"character\"].to(DEVICE)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = net(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            # Metrics\n",
        "            epoch_loss += loss\n",
        "            total += labels.size(0)\n",
        "            correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
        "        epoch_loss /= len(trainloader.dataset)\n",
        "        epoch_acc = correct / total\n",
        "        if verbose:\n",
        "            print(f\"Epoch {epoch+1}: train loss {epoch_loss}, accuracy {epoch_acc}\")\n",
        "\n",
        "\n",
        "def test(net, testloader):\n",
        "    \"\"\"Evaluate the network on the entire test set.\"\"\"\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    correct, total, loss = 0, 0, 0.0\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in testloader:\n",
        "            images, labels = batch[\"image\"].to(DEVICE), batch[\"character\"].to(DEVICE)\n",
        "            outputs = net(images)\n",
        "            loss += criterion(outputs, labels).item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    loss /= len(testloader.dataset)\n",
        "    accuracy = correct / total\n",
        "    return loss, accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQth4zTjvHoi"
      },
      "source": [
        "Train model and gather metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-3CLcjBbvI5S",
        "outputId": "25943af8-4755-4905-b1fb-4c1a79f08f30"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "trainloader, valloader, testloader = load_datasets(partition_id=0)\n",
        "net = Net().to(DEVICE)\n",
        "\n",
        "for epoch in range(5):\n",
        "  train(net, trainloader, 5)\n",
        "  loss, accuracy = test(net, valloader)\n",
        "  print(f\"Epoch {epoch+1}: validation loss {loss}, accuracy {accuracy}\")\n",
        "\n",
        "loss, accuracy = test(net, testloader)\n",
        "print(f\"Final test set performance:\\n\\tloss {loss}\\n\\taccuracy {accuracy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oria8K2QXISm"
      },
      "source": [
        "# Federated Learning Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhAY6xph8DEn"
      },
      "source": [
        "Create a class for writing our metrics into a csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HniG0D1u8C4T",
        "outputId": "8c6f7d3c-6bcb-49b7-a6cb-0596276d4c8a"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "# MetricsWriter class in charge of writing all metrics results to a CSV file\n",
        "class MetricsWriter:\n",
        "  def __init__(self, filename: str):\n",
        "    self.filename = filename\n",
        "    self.file_path = os.path.join('/content', self.filename)\n",
        "    if not os.path.exists(self.file_path):\n",
        "      self.metrics = pd.DataFrame(columns=[\"client_id\", \"loss\", \"accuracy\"])\n",
        "    else:\n",
        "      self.metrics = pd.read_csv(self.file_path)\n",
        "\n",
        "  def write_per_client(self, client_id: int, loss: float, accuracy: float):\n",
        "    new_row = pd.DataFrame({\"client_id\": client_id, \"loss\": loss, \"accuracy\": accuracy}, index=[0])\n",
        "    self.metrics = pd.concat([self.metrics, new_row], ignore_index=True)\n",
        "    self.metrics.to_csv(self.filename, index=False)\n",
        "\n",
        "  def write_aggregated(self, round: int, loss: float, accuracy: float):\n",
        "    new_row = pd.DataFrame({\"round\": round, \"agg_loss\": loss, \"agg_accuracy\": accuracy}, index=[0])\n",
        "    self.metrics = pd.concat([self.metrics, new_row], ignore_index=True)\n",
        "    self.metrics.to_csv(self.filename, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRQRXCDtZhqO"
      },
      "source": [
        "This defines the helper methods for upating model parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6OaITZypXLIm"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "def set_parameters(net, parameters: list[np.ndarray]):\n",
        "  \"\"\" Used to update the local model with parameters received from the server \"\"\"\n",
        "  params_dict = zip(net.state_dict().keys(), parameters)\n",
        "  state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
        "  net.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "\n",
        "def get_parameters(net) -> list[np.ndarray]:\n",
        "  \"\"\" Used to get the parameters from the local model \"\"\"\n",
        "  return [val.cpu().numpy() for _, val in net.state_dict().items()]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_0nSCQyZxKs"
      },
      "source": [
        "This next part creates a Client Application"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vE9dIVvnZ54v"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "class FlowerClient(NumPyClient):\n",
        "    \"\"\" This is a class for a Federated Learning Client.\n",
        "\n",
        "    It defines the methods that a client can use for local training\n",
        "    and evaluation of the local model. Each instnace of the class represents\n",
        "    a single client.\n",
        "    \"\"\"\n",
        "    def __init__(self, net, trainloader, valloader, partition_id):\n",
        "      self.net = net\n",
        "      self.trainloader = trainloader\n",
        "      self.valloader = valloader\n",
        "      self.partition_id = partition_id\n",
        "\n",
        "    def get_parameters(self, config):\n",
        "      \"\"\" Get the parameters of the model \"\"\"\n",
        "      return get_parameters(self.net)\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "      \"\"\" Get parameters from server, train model, return to server.\n",
        "\n",
        "      This method recieves the model parameters from the server and then\n",
        "      trains the model on the local data. After that, the updated model\n",
        "      parameters are returned to the server.\n",
        "      \"\"\"\n",
        "      set_parameters(self.net, parameters)\n",
        "      train(self.net, self.trainloader, epochs=1)\n",
        "      return get_parameters(self.net), len(self.trainloader), {}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "      \"\"\" Get parameters from server, evaluate model, return to server.\n",
        "\n",
        "      This method recieves the model parameters from the server and then\n",
        "      evaluates the model on the local data. After that, the evaluation\n",
        "      results are returned to the server.\n",
        "      \"\"\"\n",
        "      set_parameters(self.net, parameters)\n",
        "      loss, accuracy = test(self.net, self.valloader)\n",
        "\n",
        "      writer = MetricsWriter(filename=\"metrics_per_client.csv\")\n",
        "      writer.write_per_client(client_id=self.partition_id, loss=loss, accuracy=accuracy)\n",
        "\n",
        "      return float(loss), len(self.valloader), {\"client_id\": self.partition_id, \"accuracy\": float(accuracy), \"loss\": float(loss)}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVxRM9LsiBzC"
      },
      "source": [
        "This is the function that retrieves an instance of a client. Once the client has done it's job it will be discarded to free up memory space. This is done because in our case, all the clients and the server are existing on the same machine.\n",
        "\n",
        "\n",
        "The client object is an instance of ClientApp which will automatically select a client to run training and evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EKdekjCHdqfT"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "def client_fn(context: Context) -> Client:\n",
        "  \"\"\"Create a Flower client representing a single organization.\n",
        "\n",
        "  This method will return an instance of a particular client to call\n",
        "  fit or evaluate. The client is then discarded after use. This frees up\n",
        "  memory usage since all clients and the server are being hosted on the\n",
        "  same machine.\n",
        "  \"\"\"\n",
        "\n",
        "  # Load model\n",
        "  net = Net().to(DEVICE)\n",
        "\n",
        "  # Load data (CIFAR-10)\n",
        "  # Note: each client gets a different trainloader/valloader, so each client\n",
        "  # will train and evaluate on their own unique data partition\n",
        "  # Read the node_config to fetch data partition associated to this node\n",
        "  partition_id = context.node_config[\"partition-id\"]\n",
        "  trainloader, valloader, _ = load_datasets(partition_id=partition_id)\n",
        "\n",
        "  # Create a single Flower client representing a single organization\n",
        "  # FlowerClient is a subclass of NumPyClient, so we need to call .to_client()\n",
        "  # to convert it to a subclass of `flwr.client.Client`\n",
        "  return FlowerClient(net, trainloader, valloader, partition_id).to_client()\n",
        "\n",
        "\n",
        "# Create the ClientApp\n",
        "client = ClientApp(client_fn=client_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4vw4gYEOMNd"
      },
      "source": [
        "Create a custom Strategy class that is a subset of FedAvg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qAd7jY2sOPnU"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "class AggregateCustomMetricStrategy(FedAvg):\n",
        "    def aggregate_evaluate(\n",
        "        self,\n",
        "        server_round: int,\n",
        "        results: List[Tuple[ClientProxy, EvaluateRes]],\n",
        "        failures: List[Union[Tuple[ClientProxy, FitRes], BaseException]],\n",
        "    ) -> Tuple[Optional[float], Dict[str, Scalar]]:\n",
        "        \"\"\"Aggregate evaluation accuracy using weighted average.\"\"\"\n",
        "\n",
        "        if not results:\n",
        "            return None, {}\n",
        "\n",
        "        # Call aggregate_evaluate from base class (FedAvg) to aggregate loss and metrics\n",
        "        aggregated_loss, aggregated_metrics = super().aggregate_evaluate(\n",
        "            server_round, results, failures\n",
        "        )\n",
        "\n",
        "        # Weigh accuracy of each client by number of examples used\n",
        "        accuracies = [r.metrics[\"accuracy\"] * r.num_examples for _, r in results]\n",
        "        examples = [r.num_examples for _, r in results]\n",
        "\n",
        "        # Aggregate accuracy\n",
        "        aggregated_accuracy = sum(accuracies) / sum(examples)\n",
        "\n",
        "        # Write aggregated accuracy to our metrics CSV file\n",
        "        writer = MetricsWriter(filename=\"metrics.csv\")\n",
        "        writer.write_aggregated(round=server_round, loss=aggregated_loss, accuracy=aggregated_accuracy)\n",
        "\n",
        "        # For each of our client's results, write the client id, loss and accuracy to our metrics CSV file\n",
        "        for _, r in results:\n",
        "          writer.write_per_client(client_id=r.metrics[\"client_id\"], loss=r.metrics[\"loss\"], accuracy=r.metrics[\"accuracy\"])\n",
        "\n",
        "\n",
        "        # Return aggregated loss and metrics (i.e., aggregated accuracy)\n",
        "        return aggregated_loss, {\"accuracy\": aggregated_accuracy}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CDtMaK6AnX-K"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "def weighted_average(metrics: list[tuple[int, Metrics]]) -> Metrics:\n",
        "  # Multiply accuracy of each client by number of examples used\n",
        "  accuracies = [num_examples * m[\"accuracy\"] for num_examples, m in metrics]\n",
        "  examples = [num_examples for num_examples, _ in metrics]\n",
        "\n",
        "  # Aggregate and return custom metric (weighted average)\n",
        "  return {\"accuracy\": sum(accuracies) / sum(examples)}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Xen91tWkBAF"
      },
      "source": [
        "This is the function that creates an instance of a server. It uses an instance of ServerConfig and the Federated Learning strategy to create a ServerAppComponents object containing all of the settings that define the behavior of the server"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PK12ACiSkAtL"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "def server_fn(context: Context) -> ServerAppComponents:\n",
        "  \"\"\"Construct components that set the ServerApp behaviour.\n",
        "\n",
        "  Uses an instance of ServerConfig and the Federated Learning strategy\n",
        "  to create a ServerAppComponents object containing all of the settings\n",
        "  that define the behavior of the ServerApp.\n",
        "  \"\"\"\n",
        "\n",
        "  # Create FedAvg strategy\n",
        "  # This is the Federated Learning strategy that details the approach\n",
        "  #   to the federated learning. This one uses the built-in\n",
        "  #   Federated Averaging (FedAvg) with some customizations.\n",
        "\n",
        "  #strategy = FedAvg(\n",
        "      #fraction_fit=1.0,  # Sample 100% of available clients for training\n",
        "      #fraction_evaluate=1.0,  # Sample 50% of available clients for evaluation\n",
        "      #min_fit_clients=10,  # Never sample fewer than 10 clients for training\n",
        "      #min_evaluate_clients=10,  # Never sample fewer than 5 clients for evaluation\n",
        "      #min_available_clients=10,  # Wait until all 10 clients are available\n",
        "      #evaluate_metrics_aggregation_fn=weighted_average, # use the weighted_average\n",
        "  #)\n",
        "\n",
        "  strategy = AggregateCustomMetricStrategy(\n",
        "      fraction_fit=1.0,  # Sample 100% of available clients for training\n",
        "      fraction_evaluate=1.0,  # Sample 50% of available clients for evaluation\n",
        "      min_fit_clients=10,  # Never sample fewer than 10 clients for training\n",
        "      min_evaluate_clients=10,  # Never sample fewer than 5 clients for evaluation\n",
        "      min_available_clients=10,  # Wait until all 10 clients are available\n",
        "      # evaluate_metrics_aggregation_fn=weighted_average, # use the weighted_average\n",
        "  )\n",
        "\n",
        "  # Configure the server for 5 rounds of training\n",
        "  config = ServerConfig(num_rounds=5)\n",
        "\n",
        "  return ServerAppComponents(strategy=strategy, config=config)\n",
        "\n",
        "\n",
        "# Create the ServerApp\n",
        "server = ServerApp(server_fn=server_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKavifmOlMLN"
      },
      "source": [
        "Specify the amount of resources each client can use"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tOd5CiDPkGsQ"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "# Specify the resources each of your clients need\n",
        "# By default, each client will be allocated 1x CPU and 0x GPUs\n",
        "backend_config = {\"client_resources\": {\"num_cpus\": 1, \"num_gpus\": 0.0}}\n",
        "\n",
        "\n",
        "##### May not need this if we never plan to run on CUDA\n",
        "# When running on GPU, assign an entire GPU for each client\n",
        "if DEVICE.type == \"cuda\":\n",
        "  backend_config = {\"client_resources\": {\"num_cpus\": 1, \"num_gpus\": 1.0}}\n",
        "  # Refer to our Flower framework documentation for more details about Flower simulations\n",
        "  # and how to set up the `backend_config`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q39DOlN9lrWF"
      },
      "source": [
        "Run the simulation with the specified server, client app, number of nodes and backend_config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4eoYPWKltDM",
        "outputId": "760afe85-5d2a-4dd0-8889-f13c1c8edc8f"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "NUM_CLIENTS = 10\n",
        "\n",
        "\n",
        "run_simulation(\n",
        "  server_app=server,\n",
        "  client_app=client,\n",
        "  num_supernodes=NUM_CLIENTS,\n",
        "  backend_config=backend_config,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_t5YYJfpOe6"
      },
      "source": [
        "Visualization of Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "POg8lxMAcm-W"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "def visualize_results(file_name):\n",
        "  # Read the CSV file\n",
        "  file_path = os.path.join('/content', file_name)\n",
        "  data = pd.read_csv(file_path)\n",
        "\n",
        "  # Fill in round number for\n",
        "  data['round'] = data['round'].fillna(method='ffill')\n",
        "\n",
        "  # Drop rows where 'client_id' is NaN, to avoid plotting aggregated data as individual clients\n",
        "  client_data = data.dropna(subset=['client_id'])\n",
        "\n",
        "  # Create a figure with subplots\n",
        "  fig, axis = plt.subplots(2, 2, figsize=(12, 10))\n",
        "  fig.suptitle('Federated Learning Metrics', fontsize=16)\n",
        "\n",
        "  # 1. History of loss per client over rounds\n",
        "  for client_id in client_data['client_id'].unique():\n",
        "    client_df = client_data[client_data['client_id'] == client_id]\n",
        "    axis[0, 0].plot(client_df['round'], client_df['loss'], marker='o', label=f'Client {client_id}')\n",
        "\n",
        "  axis[0, 0].set_title('Loss per Client Over Rounds')\n",
        "  axis[0, 0].set_xlabel('Rounds')\n",
        "  axis[0, 0].set_ylabel('Loss')\n",
        "  axis[0, 0].legend()\n",
        "  axis[0, 0].grid()\n",
        "\n",
        "  # 2. History of average loss among clients over rounds\n",
        "  average_loss = data.groupby('round')['agg_loss'].mean()\n",
        "  axis[0, 1].plot(average_loss.index, average_loss.values, marker='o', color='orange')\n",
        "  axis[0, 1].set_title('Average Loss Among Clients Over Rounds')\n",
        "  axis[0, 1].set_xlabel('Rounds')\n",
        "  axis[0, 1].set_ylabel('Average Loss')\n",
        "  axis[0, 1].grid()\n",
        "\n",
        "  # 3. History of evaluation accuracy per client over rounds\n",
        "  for client_id in client_data['client_id'].unique():\n",
        "    client_df = client_data[client_data['client_id'] == client_id]\n",
        "    axis[1, 0].plot(client_df['round'], client_df['accuracy'], marker='o', label=f'Client {client_id}')\n",
        "\n",
        "  axis[1, 0].set_title('Evaluation Accuracy per Client Over Rounds')\n",
        "  axis[1, 0].set_xlabel('Rounds')\n",
        "  axis[1, 0].set_ylabel('Accuracy')\n",
        "  axis[1, 0].legend()\n",
        "  axis[1, 0].grid()\n",
        "\n",
        "  # 4. History of average evaluation accuracy among clients over rounds\n",
        "  average_accuracy = data.groupby('round')['agg_accuracy'].mean()\n",
        "  axis[1, 1].plot(average_accuracy.index, average_accuracy.values, marker='o', color='green')\n",
        "  axis[1, 1].set_title('Average Evaluation Accuracy Among Clients Over Rounds')\n",
        "  axis[1, 1].set_xlabel('Rounds')\n",
        "  axis[1, 1].set_ylabel('Average Accuracy')\n",
        "  axis[1, 1].grid()\n",
        "\n",
        "  # Adjust layout\n",
        "  plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "n3zQPkLTpeie",
        "outputId": "2ace208d-6b42-441b-e09f-808845237bb6"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "visualize_results(file_name=\"metrics.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2TTPcUdpyWc",
        "outputId": "91dd7bf9-1daf-4cbe-cb8b-91f734d3bb72"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
